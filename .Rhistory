roullete %>%
mutate(cumsum_rank = cumsum(rank))
mating_parents<-
lapply(1:(2*pop_size), select_mating_parents,
pop_size=pop_size,
roullete=roullete,
population=population)
children<-
lapply(mating_parents, crossover)
children<-
children %>% unlist(recursive = F)
children<-
children[1:pop_size]
top_parent <- roullete %>% tail(1) %>% pull(parent)
top_parent_fitness <- roullete %>% tail(1) %>% pull(fitness)
print(population[[top_parent]])
print(paste0("top parent fitness ",top_parent_fitness,collapse = " ") )
population<-
lapply(children, mutation, rate=0.1)
}
library(tidyverse)
library(caret)
library(leaps)
install.packages(c("tidyverse", "leaps"))
library(tidyverse)
library(caret)
library(leaps)
library(MASS)
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "seqrep")
summary(models)
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "forward")
summary(models)
library(leaps)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 4)
coef(step.model$finalModel, 5)
library(tidyverse)
library(caret)
library(leaps)
library(MASS)
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "forward")
summary(models)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "forward")
summary(models)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
#nvmax: the number of variable in the model. For example nvmax = 2, specify the best 2-variables model
#RMSE and MAE are two different metrics measuring the prediction error of each model. The lower the RMSE and MAE, the better the model.
#Rsquared indicates the correlation between the observed outcome values and the values predicted by the model. The higher the R squared, the better the model.
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
step.model$results
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
coef(step.model$finalModel, 5)
step.model$bestTune
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "backward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "backward")
summary(models)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
# Fit the full model
full.model <- lm(Fertility ~., data = swiss)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "backward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Fertility~., data = swiss, nvmax = 5,
method = "backward")
summary(models)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Fertility ~., data = swiss,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
library(dplyr)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
train_data <- read.csv("./Galileo/Econometria/Proyecto/train.csv", header = TRUE)
test_data <- read.csv("./Galileo/Econometria/Proyecto/test.csv", header = TRUE)
head(test_data)
#++++++++++++++++++++++++++++++++++++++++++++++++
# USING STEPWISE
full.model <- lm(Chance.of.Admit ~., data = swiss)
#++++++++++++++++++++++++++++++++++++++++++++++++
# USING STEPWISE
full.model <- lm(Chance.of.Admit ~., data = train_data)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
library(tidyverse)
library(caret)
library(leaps)
library(MASS)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
models <- regsubsets(Chance.of.Admit~., data = train_data, nvmax = 5,
method = "forward")
summary(models)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Chance.of.Admit ~., data = train_data,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
cormat <- round(cor(train_data),2)
head(cormat)
ggcorrplot(cormat, hc.order = TRUE, type = "lower",
lab = TRUE)
library(dplyr)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
library(tidyverse)
library(caret)
library(leaps)
library(MASS)
train_data <- read.csv("./Galileo/Econometria/Proyecto/train.csv", header = TRUE)
test_data <- read.csv("./Galileo/Econometria/Proyecto/test.csv", header = TRUE)
head(test_data)
head(train_data)
cormat <- round(cor(train_data),2)
head(cormat)
ggcorrplot(cormat, hc.order = TRUE, type = "lower",
lab = TRUE)
lm.fit <- lm(Chance.of.Admit~TOEFL.Score+GRE.Score+CGPA, data = train_data)
lm2.fit <- lm(Chance.of.Admit~TOEFL.Score+GRE.Score+CGPA+LOR^2+Research^3, data = train_data)
summary(lm2.fit)
library(dplyr)
library(readr)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
data <- read_csv("top50.csv")
View(data)
head(data)
scatter.smooth(x=data$Popularity, y=data$Danceability, main="Danceability ~ Popularity")
head(data)
scatter.smooth(x=data$Popularity, y=data$Speechiness, main="Speechiness ~ Popularity")
scatter.smooth(x=data$Popularity, y=data$Beats.Per.Minute, main="Beats.Per.Minute ~ Popularity")
cor(data$Popularity, data$Speechiness)
cor(data$Popularity, data$Speechiness)
cor(data$Popularity, data$Speechiness.)
scatter.smooth(x=data$Popularity, y=data$Speechiness., main="Speechiness ~ Popularity")
head(data)
cor(data$Popularity, data$Genre)
cor(data$Popularity, data$Beats.Per.Minute)
cor(data$Popularity, data$Energy)
cor(data$Popularity, data$Danceability)
cor(data$Popularity, data$Loudness..dB..)
cor(data$Popularity, data$Liveness)
cor(data$Popularity, data$Valence.)
cor(data$Popularity, data$Length.)
cor(data$Popularity, data$Acousticness..)
cor(data$Popularity, data$Energy)
linearMod <- lm(Popularity ~ Valence + Beats.Per.Minute + Speechiness., data=data)
linearMod <- lm(Popularity ~ Valence. + Beats.Per.Minute + Speechiness., data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(Popularity ~ Speechiness., data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(Popularity ~ Valence. , data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(Popularity ~ + Beats.Per.Minute, data=data)
print(linearMod)
summary(linearMod)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
data <- read_csv("pulsar_stars.csv")
View(data)
head(data)
cor(data, method = c("pearson", "kendall", "spearman"))
cor(data)
res <- cor(data)
round(res, 2)
install.packages("corrplot")
library(corrplot)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
data <- read_csv("pulsar_stars.csv")
data %>%
rename(
'Mean of the integrated profile' = Mean.ip,
'Standard deviation of the integrated profile' = std.ip,
'Excess kurtosis of the integrated profile' = Excess.kurtosis.ip,
'Skewness of the integrated profile' = Skewness.ip,
'Mean of the DM-SNR curve' = Mean.DMSNR.curve,
'Standard deviation of the DM-SNR curve' = std.DMSNR.curve,
'Excess kurtosis of the DM-SNR curve'= Excess.kurtosis.DMSNR.curve,
'Skewness of the DM-SNR curve' = Skewness.DMSNR.curve,
'target_class' = target_class
)
library(tidyverse)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
data <- read_csv("pulsar_stars.csv")
data %>%
rename(
'Mean of the integrated profile' = Mean.ip,
'Standard deviation of the integrated profile' = std.ip,
'Excess kurtosis of the integrated profile' = Excess.kurtosis.ip,
'Skewness of the integrated profile' = Skewness.ip,
'Mean of the DM-SNR curve' = Mean.DMSNR.curve,
'Standard deviation of the DM-SNR curve' = std.DMSNR.curve,
'Excess kurtosis of the DM-SNR curve'= Excess.kurtosis.DMSNR.curve,
'Skewness of the DM-SNR curve' = Skewness.DMSNR.curve,
'target_class' = target_class
)
data <- as_tibble(data)
data %>%
rename(
'Mean of the integrated profile' = Mean.ip,
'Standard deviation of the integrated profile' = std.ip,
'Excess kurtosis of the integrated profile' = Excess.kurtosis.ip,
'Skewness of the integrated profile' = Skewness.ip,
'Mean of the DM-SNR curve' = Mean.DMSNR.curve,
'Standard deviation of the DM-SNR curve' = std.DMSNR.curve,
'Excess kurtosis of the DM-SNR curve'= Excess.kurtosis.DMSNR.curve,
'Skewness of the DM-SNR curve' = Skewness.DMSNR.curve,
'target_class' = target_class
)
head(data)
data <- as_tibble(data)
data %>%
rename(
Mean.ip = 'Mean of the integrated profile',
std.ip = 'Standard deviation of the integrated profile',
Excess.kurtosis.ip = 'Excess kurtosis of the integrated profile',
Skewness.ip = 'Skewness of the integrated profile',
Mean.DMSNR.curve = 'Mean of the DM-SNR curve',
std.DMSNR.curve = 'Standard deviation of the DM-SNR curve',
Excess.kurtosis.DMSNR.curve = 'Excess kurtosis of the DM-SNR curve',
Skewness.DMSNR.curve = 'Skewness of the DM-SNR curve',
target_class = 'target_class'
)
head(data)
colnames(data)
data <- read_csv("pulsar_stars.csv")
data <- as_tibble(data)
data %>%
rename(
Mean.ip = 'Mean of the integrated profile',
std.ip = 'Standard deviation of the integrated profile',
Excess.kurtosis.ip = 'Excess kurtosis of the integrated profile',
Skewness.ip = 'Skewness of the integrated profile',
Mean.DMSNR.curve = 'Mean of the DM-SNR curve',
std.DMSNR.curve = 'Standard deviation of the DM-SNR curve',
Excess.kurtosis.DMSNR.curve = 'Excess kurtosis of the DM-SNR curve',
Skewness.DMSNR.curve = 'Skewness of the DM-SNR curve',
target_class = 'target_class'
)
colnames(data)
data <- data %>%
rename(
Mean.ip = 'Mean of the integrated profile',
std.ip = 'Standard deviation of the integrated profile',
Excess.kurtosis.ip = 'Excess kurtosis of the integrated profile',
Skewness.ip = 'Skewness of the integrated profile',
Mean.DMSNR.curve = 'Mean of the DM-SNR curve',
std.DMSNR.curve = 'Standard deviation of the DM-SNR curve',
Excess.kurtosis.DMSNR.curve = 'Excess kurtosis of the DM-SNR curve',
Skewness.DMSNR.curve = 'Skewness of the DM-SNR curve',
target_class = 'target_class'
)
colnames(data)
res <- cor(data)
round(res, 2)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
corrplot(res, type = "full", order = "hclust",
tl.col = "black", tl.srt = 45)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip, data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(target_class ~ Excess.kurtosis.ip + Skewness.ip, data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(target_class ~ Excess.kurtosis.DMSNR.curve + std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=data)
print(linearMod)
summary(linearMod)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=data)
print(linearMod)
summary(linearMod)
colnames(data)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
res <- cor(train)
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black", tl.srt = 45)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=train)
print(linearMod)
summary(linearMod)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=train)
print(linearMod)
summary(linearMod)
Prediction <- predict(linearMod, test)
saveRDS(linearMod, "final_model.rds")
install.packages("tidyverse")
library(dplyr)
library(rpart)
library(plumber)
library(assertive)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
fit <- readRDS("final_model.rds")
library(dplyr)
library(rpart)
library(dplyr)
library(rpart)
library(plumber)
library(assertive)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
fit <- readRDS("final_model.rds")
#* @apiTitle Predicting a Pulsar Star
#* @apiDescription Predicting if is a pulsar star based on data
#' @param std.DMSNR.curve Standard deviation of the DM-SNR curve
#' @param Excess.kurtosis.ip Excess kurtosis of the integrated profile
#' @param Skewness.ip Skewness of the integrated profile
#' @param Mean.ip Mean of the integrated profile
#' @post /stars
function(std.DMSNR.curve, Excess.kurtosis.ip, Skewness.ip, Mean.ip){
features <- data_frame('std.DMSNR.curve'= as.numeric(std.DMSNR.curve),
'Excess.kurtosis.ip'= as.numeric(Excess.kurtosis.ip),
'Skewness.ip'= as.numeric(Skewness.ip),
'Mean.ip' = as.numeric(Mean.ip)
)
out<-predict(fit, features)
as.character(out)
}
library(plumber)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
r <- plumb("prediction_api.R")
r <- plumb("prediction_api.R")
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
r <- plumb("prediction_api.R")
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto/api')
r <- plumb("prediction_api.R")
r$run(host = "0.0.0.0", port = 8001)
library(dplyr)
library(readr)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(corrplot)
library(tidyverse)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto')
data <- read_csv("pulsar_stars.csv")
data <- as_tibble(data)
data <- data %>%
rename(
Mean.ip = 'Mean of the integrated profile',
std.ip = 'Standard deviation of the integrated profile',
Excess.kurtosis.ip = 'Excess kurtosis of the integrated profile',
Skewness.ip = 'Skewness of the integrated profile',
Mean.DMSNR.curve = 'Mean of the DM-SNR curve',
std.DMSNR.curve = 'Standard deviation of the DM-SNR curve',
Excess.kurtosis.DMSNR.curve = 'Excess kurtosis of the DM-SNR curve',
Skewness.DMSNR.curve = 'Skewness of the DM-SNR curve',
target_class = 'target_class'
)
colnames(data)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
res <- cor(train)
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black", tl.srt = 45)
linearMod <- lm(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip, data=train)
print(linearMod)
summary(linearMod)
Prediction <- predict(linearMod, test)
saveRDS(linearMod, "final_model_ref.rds")
classification <- rpart(target_class ~ std.DMSNR.curve + Excess.kurtosis.ip + Skewness.ip + Mean.ip,
method="class", data=train)
print(classification)
summary(classification)
Prediction <- predict(classification, test)
saveRDS(classification, "final_model_class.rds")
r$run(host = "0.0.0.0", port = 8001)
library(plumber)
setwd('/Users/alanhurtarte/Galileo/Product Dev/Proyecto/api')
r <- plumb("prediction_api.R")
r$run(host = "0.0.0.0", port = 8001)
r$run(host = "0.0.0.0", port = 8001)
r$run(host = "0.0.0.0", port = 8001)
